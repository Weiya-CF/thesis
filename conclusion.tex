\chapter*{Conclusion}
\markboth{\MakeUppercase{Conclusion}}{}
%\addcontentsline{toc}{chapter}{Conclusion}

\mtcaddchapter[Conclusion]

\section*{General Conclusion}

Multi-user display technology makes it possible for several users to experience visual immersion simultaneously inside the same immersive system. Under the circumstance, co-located users share the same virtual environment on top of a common physical workspace, which requires them to handle physical constrains from the real world while immersed in the virtual world.

This dissertation describes our efforts in aim to support collaborative work among co-located users in multi-user immersive virtual environments.

Depending on the relationship between users' spatial reference frames, we defined two complementary modes of collaboration - consistent and individual mode, which are both useful by supporting collaborative work in different ways. Our goal is to study issues related to individual mode in order to design a valid and efficient framework covering both collaborative modes for co-located collaboration in immersive virtual environment. We identified two categories of spatial issues related to the use of individual mode: perceptual conflicts during user communication and interaction, and cohabitation in limited physical workspace during individual navigation. Our research work is then organized around the study of these two aspects.

First, we conducted an experiment to test users' reactions to perceptual conflicts due to the introduced avatar representation for co-located collaboration. We wanted to examine how perceptual conflicts generated by the dual-presence of a user's physical body and the associated avatar would alter users' communication and their task performance. We artificially created conflicting situations and accentuated them with instructions involving spatial information. The result showed that, the dual-presence induced 33\% of participants to interact with the real collaborator than her avatar, and this choice was made at the beginning and stayed stable till the end. Moreover, users' task performance was not influenced by the distance between the two forms of collaborator, and users took longer time to react to instructions containing deictic gestures than verbal commands.

So when users faced the dual-presence of collaborator, it seemed that the cognitive process helped them to solve the perceptual conflicts and allowed them to follow a coherent strategy. However, it was at a cost of task performance for instructions that involved gesture information. Although further studies are needed to get a more general conclusion, we can already say that in individual mode, it is preferable to avoid perceiving the dual-presence during collaboration, especially when user communication involves spatial information.

Second, we studied issues related to physical workspace management for co-located users. We summarized cohabitation problems along with corresponding measurement metrics in terms of spatial relationship between users and workspace boundaries, and also workspace arrangement among co-located users. Then we concentrated on the design and evaluation of appropriate navigation paradigms to allow individual navigation while solving user cohabitation problems. The paradigm that we proposed was an altered version of Human Joystick metaphor that included additional controls to manage users' relationship with system borders and to minimize inter-user interferences.

We conducted a series of user evaluations to investigate the influence of each alteration by testing their combinations with various navigation tasks. Results showed that modified transfer functions largely improved users' cohabitation situation both for translation and rotation by providing a larger velocity range with relatively small base gain value compared to linear ones. Adaptive neutral orientations can efficiently reduce user's perception of physical environment, whereas adaptive neutral positions only showed some potential benefits and needed to be further developed.

At last, based on observations and feedback from user cohabitation study, we designed a dynamic navigation model named DYNAMIC. It is a generic version of altered human joystick, which integrates obstacles in the physical workspace by a potential field method to solve user cohabitation problems, and constrains from virtual world to enable interactive control of a user's vehicle and different levels of interaction between users. This model has several advantages: it offers a generic solution for user cohabitation in terms of supported number of user and type of immersive systems, and it allows flexible instantiation of transfer functions with adaptive parameter settings. It enriches collaborative scenarios by enabling collaborative modes switching and could also be extended to support remote collaboration.

Although our research is initially motivated by supporting co-located collaboration in large-scale multi-user immersive virtual environment, and experiments described in this thesis are conducted in a multi-user CAVE system, most of our observations and developed paradigms are applicable to other types of immersive devices (e.g. multiple HMDs), so our work contributes to co-located collaboration from a more generic perspective. Also, as the dynamic model can be extended to manage collaboration among remote sites, we make one step further towards a collaborative framework involving both remote and co-located users connected by immersive virtual environments.

\section*{Future Work}

This thesis presented some basic concepts and several paradigms that we designed to support co-located immersive collaboration, while there are still many questions to be answered and new directions to be explored in the future. Moreover, by searching solutions to manage user cohabitation, we arrive at a dynamic model supporting different immersive systems with a generic control process, which also leads us to new research challenges on the way to fully support immersive collaboration.

\subsection*{Perceptual Conflicts}
Regarding future studies on perceptual conflicts, a first complementary study that we can carry out is to explicitly ask users to follow the collaborator's avatar despite the perception of the dual-presence to observe their reaction and to compare their performance with the results of previous experiment, especially for whose were in the Real and Mixed group.

Second, tasks that require more complicated interactions and have longer duration between collaborators could be tested to further investigate the impact of certain factors on task performance.

Additionally, the effects of visual-auditive conflicts were not yet assessed. Users may have different spatial relationship (have a large or medium distance) in the virtual world while staying side-by-side in the physical workspace, which may influence users' comprehension of the situation. So we need to test whether we should use headphones to map users' speech to avatars' positions by 3D audio, or more generally in term of design choice, whether do we need to completely separate co-located users in individual mode by putting them in a pseudo-remote situation, or the displaced audio has little effect and we can let users talk directly without computer mediation.

\subsection*{Collaborative Mode Switching}
The dynamic model allows automatic transition between consistent mode and individual mode with predefined virtual locations for collaboration. Consequently, we need a standard procedure to define these collaboration spots according to the properties of immersive systems. For example, if users need to collaborate within a space (e.g. at two different sides of a plane) larger than the immersive system (CAVE-like system or room for HMDs), in this situation consistent mode is impossible. However, if users just need to work around a table, then we can put spots with attractive potential field around it and activate mode switching. More generally, a task-oriented collaboration model is needed so that we can divide a complex collaborative task into different phases and associate appropriate collaborative modes accordingly. 

Moreover, in CAVE-like systems, mode switching is a critical moment in term of perception as users are ``merging" or ``splitting" with their avatars from other users' perspectives. So further study on perceptual conflicts will also help us to better understand the effects of dual-presence in this particular situation.

\subsection*{Navigation}
The dynamic model allows adaptive parameter settings and we identified a list of potential influencing factors (section~\ref{sec:para_set}). The next question is how we can take into account these factors to improve the dynamic model in terms of user comfort and stability during navigation.

In term of users' comfort, an important question is that in general, how we can find appropriate parameters (e.g. gain value for the transfer function and the inverse model) for the dynamic model with all these user-related factors. So whether do we need a calibration process to identify parameters for each user, or can we find parameters that correspond to a generic model describing human reaction to accelerations? Furthermore, we need a more complete model to describe human activity in immersive virtual environment. For example, instead of using information relative to a user's head, torso or part of the limb, it would be interesting to model the motion of the whole body to better express a user's moving intention and real world dynamics.

Another important factor that we should consider for virtual navigation is user's cybersickness. In the experiments that we conducted, we used subjective questionnaire to assess the severity of cybersickness symptoms. The problem is that with the questionnaire, we can only get a description of user's feeling afterwards, it is impossible to observe the trends of cybersickness variation during the simulation to see its interaction effect with modified navigation controls. If we can get more information about the cause and influencing factors of cybersickness, it will then be possible for us to improve the dynamic model by including another constrain - targeting cybersickness minimization.

Finally, advanced viewpoint controls in immersive systems for perspective change (e.g. from first person to third person, zoom in or out, etc.) could be integrated to further facilitate the execution of collaborative tasks.

\subsection*{Priority Management}
The dynamic model unifies constrains from the physical workspace and virtual world, which facilitates system design. However, it could be troublesome if we simply sum up all the constrains to get the final acceleration. For example, when a user is near the physical workspace border, it may happen that accelerations generated by virtual constrains could neutralize the accelerations for obstacle avoidance, which would invalidate safety measures and lead the user to a dangerous situation. Also, a user could be cornered by the sum of different constrains with inadequate personal workspace when three or more users are present in the same workspace. So it is important to assign different priorities to diverse constrains: safety constrains should come before all the others, and we need to amplify constrains that encourage the redistribution of workspace among different actors to get them out of blocking situations. In certain cases, it may be helpful to add additional feedback (visual or auditive) if the constrains fail to assure a proper distribution of users with respect to the physical workspace.

Furthermore, as discussed in the last chapter, the dynamic model could be extended to manage the coexistence of users with robotic devices (e.g. haptic arms) during immersive collaboration. We need to design proper control laws to intelligently position the arm with respect to its master and other co-located users in real time, and similarly, we should be able to modulate constrains to leave enough workspace for the arm as for the users.

